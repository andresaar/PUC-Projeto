{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script has the objective of downloading and keep traceability information about Piano MIDI files from the Mutopia Project site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy import Selector, Spider, Request\n",
    "from scrapy.pipelines.files import FilesPipeline\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "from crochet import setup, wait_for\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDIDownloadPipeline(FilesPipeline):\n",
    "    def file_path(self, request, response=None, info=None, *, item=None):\n",
    "        media_ext = os.path.splitext(request.url)[1]\n",
    "        media_name = self.remove_non_ascii(item.get('name'))\n",
    "        return f'{media_name}{media_ext}'\n",
    "\n",
    "    def remove_non_ascii(self, string):\n",
    "        return ''.join([i if 47 < ord(i) < 58 or 64 < ord(i) < 91 or i == '_' \\\n",
    "            else '' for i in string.upper().replace(\" \", \"_\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDIDownloadAndTrack(Spider):\n",
    "    name = \"MIDI Download and Track in CSV\"\n",
    "    start_urls = [\"https://www.mutopiaproject.org/cgibin/make-table.cgi?Instrument=Piano\"]\n",
    "    custom_settings = {\n",
    "        'ITEM_PIPELINES': {\n",
    "            '__main__.MIDIDownloadPipeline': 1,\n",
    "        },\n",
    "        'FILES_STORE': '../midi/downloaded_midi',\n",
    "        'FEEDS': {\n",
    "            \"midi_info.csv\": {\n",
    "                'format': \"csv\",\n",
    "                'overwrite': True,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    def parse(self, response):\n",
    "        page_cnt = 1 if 'startat' not in response.url else int(re.search('startat=(\\\\d+)', response.url).group(1))//10 + 1\n",
    "        print(f\"Parsing page {page_cnt}...\")\n",
    "        for midi in response.xpath(\"//table[contains(@class, 'result-table')]\").getall():\n",
    "            midi_info = Selector(text=midi).xpath(\"//td\").getall()\n",
    "            midi_url = [Selector(text=each).xpath(\"//@href\").get() for each in midi_info if \".mid\" in each][0]\n",
    "            midi_info = [Selector(text=each).xpath(\"//text()\").get() for each in midi_info]\n",
    "            if not re.search('\\\\.mid$', midi_url):\n",
    "                continue\n",
    "            yield {\n",
    "                \"name\": midi_info[0],\n",
    "                \"author\": midi_info[1][3:],\n",
    "                \"instruments\": midi_info[4][4:],\n",
    "                \"domain\": midi_info[9],\n",
    "                \"file_urls\": [midi_url]\n",
    "                }\n",
    "        next_page_url = response.xpath(\"//a[contains(text(), 'Next 10')]/@href\").get()\n",
    "        if next_page_url:\n",
    "            yield Request(response.urljoin(next_page_url), self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@wait_for(5*60)\n",
    "def run_spider():\n",
    "    crawler = CrawlerRunner()\n",
    "    ret = crawler.crawl(MIDIDownloadAndTrack)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing page 1...\n",
      "Parsing page 2...\n",
      "Parsing page 3...\n",
      "Parsing page 4...\n",
      "Parsing page 5...\n",
      "Parsing page 6...\n",
      "Parsing page 7...\n",
      "Parsing page 8...\n",
      "Parsing page 9...\n",
      "Parsing page 10...\n",
      "Parsing page 11...\n",
      "Parsing page 12...\n",
      "Parsing page 13...\n",
      "Parsing page 14...\n",
      "Parsing page 15...\n",
      "Parsing page 16...\n",
      "Parsing page 17...\n",
      "Parsing page 18...\n",
      "Parsing page 19...\n",
      "Parsing page 20...\n",
      "Parsing page 21...\n",
      "Parsing page 22...\n",
      "Parsing page 23...\n",
      "Parsing page 24...\n",
      "Parsing page 25...\n",
      "Parsing page 26...\n",
      "Parsing page 27...\n",
      "Parsing page 28...\n",
      "Parsing page 29...\n",
      "Parsing page 30...\n",
      "Parsing page 31...\n",
      "Parsing page 32...\n",
      "Parsing page 33...\n",
      "Parsing page 34...\n",
      "Parsing page 35...\n",
      "Parsing page 36...\n",
      "Parsing page 37...\n",
      "Parsing page 38...\n",
      "Parsing page 39...\n",
      "Parsing page 40...\n",
      "Parsing page 41...\n",
      "Parsing page 42...\n",
      "Parsing page 43...\n",
      "Parsing page 44...\n",
      "Parsing page 45...\n",
      "Parsing page 46...\n",
      "Parsing page 47...\n",
      "Parsing page 48...\n",
      "Parsing page 49...\n",
      "Parsing page 50...\n",
      "Parsing page 51...\n",
      "Parsing page 52...\n",
      "Parsing page 53...\n",
      "Parsing page 54...\n",
      "Parsing page 55...\n",
      "Parsing page 56...\n",
      "Parsing page 57...\n",
      "Parsing page 58...\n",
      "Parsing page 59...\n",
      "Parsing page 60...\n",
      "Parsing page 61...\n",
      "Parsing page 62...\n",
      "Parsing page 63...\n",
      "Parsing page 64...\n",
      "Parsing page 65...\n",
      "Parsing page 66...\n",
      "Parsing page 67...\n",
      "Parsing page 68...\n",
      "Parsing page 69...\n",
      "Parsing page 70...\n",
      "Parsing page 71...\n",
      "Parsing page 72...\n",
      "Parsing page 73...\n",
      "Parsing page 74...\n",
      "Parsing page 75...\n",
      "Parsing page 76...\n",
      "Parsing page 77...\n",
      "Parsing page 78...\n",
      "Parsing page 79...\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('../midi/downloaded_midi/*')\n",
    "for file in files:\n",
    "    os.remove(file)\n",
    "run_spider()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93f05f2af20d9a618d26a8ffda4f3752ddcdcb4dc88f5cc382466b87115fd2ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
