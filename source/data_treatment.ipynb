{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDI to RNN Input data treatment\n",
    "\n",
    "This script was implemented to transform the pre-treated midi data to value arrays that can be served as input for the RNN training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIDI data attributes analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acoustic Grand Piano\n",
      "Note(start=0.000000, end=0.136364, pitch=76, velocity=60)\n"
     ]
    }
   ],
   "source": [
    "midi_files = glob.glob(r\"..\\midi\\treated_midi\\*\")\n",
    "midi_file = pretty_midi.PrettyMIDI(midi_files[0])\n",
    "\n",
    "instrument = midi_file.instruments[0]\n",
    "print(pretty_midi.program_to_instrument_name(instrument.program))\n",
    "\n",
    "note = instrument.notes[0]\n",
    "print(note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the previous snippet, the Note class has four attributes:\n",
    "* **start**: time when the note starts (in seconds)\n",
    "* **end**: time when the note ends (in seconds)\n",
    "* **pitch**: pitch of the note (can be associated with the piano key)\n",
    "* **velocity**: information on the volume of the note - during pre-treatment all notes were set with velocity of 60.\n",
    "\n",
    "We can disconsider the velocity information, as it has no relevant information for the structure of the song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the data can be moved to an dictionary of dataframes, in which every single dataframe corresponds to a song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160_EIGHTMEASURE_EXERCISES_NO_1\n",
      "----------------------------------------\n",
      "         start        end  pitch\n",
      "0     0.000000   0.136364     76\n",
      "1     0.136364   0.272727     79\n",
      "2     0.272727   0.409091     77\n",
      "3     0.000000   0.545455     60\n",
      "4     0.000000   0.545455     67\n",
      "..         ...        ...    ...\n",
      "147  15.818182  15.954545     72\n",
      "148  15.954545  16.090909     76\n",
      "149  16.090909  16.227273     79\n",
      "150  16.227273  16.363636     84\n",
      "151  16.363636  16.636364     72\n",
      "\n",
      "[152 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "for midi_file in midi_files:\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    song_dict = {\n",
    "        \"start\": [],\n",
    "        \"end\": [],\n",
    "        \"pitch\": [],\n",
    "    }\n",
    "    for note in midi_data.instruments[0].notes:\n",
    "        song_dict[\"start\"].append(note.start)\n",
    "        song_dict[\"end\"].append(note.end)\n",
    "        song_dict[\"pitch\"].append(note.pitch)\n",
    "    data_dict[midi_file.split(\"\\\\\")[-1].split(\".\")[0]] = pd.DataFrame(song_dict)\n",
    "\n",
    "dict_key = list(data_dict.keys())[0]\n",
    "print(f'{dict_key}\\n{\"-\"*40}\\n{data_dict[dict_key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitch\n",
      "Min: 0\tMax: 105\n"
     ]
    }
   ],
   "source": [
    "min_pitch, max_pitch = 0 , 0\n",
    "\n",
    "for midi_file in midi_files:\n",
    "    midi_file = pretty_midi.PrettyMIDI(midi_file)\n",
    "    notes = midi_file.instruments[0].notes\n",
    "    for note in notes:\n",
    "        min_pitch = min(min_pitch, note.pitch)\n",
    "        max_pitch = max(max_pitch, note.pitch)\n",
    "\n",
    "print(f'Pitch\\nMin: {min_pitch}\\tMax: {max_pitch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in previous snippet, the pitch of the notes vary from 0 to 105 in value, which can be translated from 8.18 Hz to 3520 Hz.\n",
    "In a regular piano, the note of 8.18Hz is not achievable. The piano notes only start from 27.50Hz, which is the note A0, in MIDI pitch value of 21.\n",
    "Having this in mind we can remove all notes under the pitch value of 21.\n",
    "\n",
    "The max pitch value of 105 (or A7, 3520Hz) is valid for piano, so we don't need to trim in the high-pitch side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,midi_file in enumerate(midi_files):\n",
    "    midi_file = pretty_midi.PrettyMIDI(midi_file)\n",
    "    notes = midi_file.instruments[0].notes\n",
    "    notes = [note for note in notes if note.pitch > 21]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9557642ed31844b903319b561864a8ef0da5c7b931996e0f6ddf8b44d6bc5235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
