{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDI to RNN Input data treatment\n",
    "\n",
    "This script was implemented to transform the pre-treated midi data to value arrays that can be served as input for the RNN training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIDI data attributes analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acoustic Grand Piano\n",
      "Note(start=0.000000, end=0.136364, pitch=76, velocity=60)\n"
     ]
    }
   ],
   "source": [
    "midi_files = glob.glob(r\"..\\midi\\treated_midi\\*\")\n",
    "midi_file = pretty_midi.PrettyMIDI(midi_files[0])\n",
    "\n",
    "instrument = midi_file.instruments[0]\n",
    "print(pretty_midi.program_to_instrument_name(instrument.program))\n",
    "\n",
    "note = instrument.notes[0]\n",
    "print(note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the previous snippet, the Note class has four attributes:\n",
    "* **start**: time when the note starts (in seconds)\n",
    "* **end**: time when the note ends (in seconds)\n",
    "* **pitch**: pitch of the note (can be associated with the piano key)\n",
    "* **velocity**: information on the volume of the note - during pre-treatment all notes were set with velocity of 60.\n",
    "\n",
    "We can disconsider the velocity information, as it has no relevant information for the structure of the song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the data can be moved to an dictionary of dataframes, in which every single dataframe corresponds to a song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160_EIGHTMEASURE_EXERCISES_NO_1\n",
      "----------------------------------------\n",
      "         start        end  pitch\n",
      "0     0.000000   0.136364     76\n",
      "3     0.000000   0.545455     60\n",
      "4     0.000000   0.545455     67\n",
      "1     0.136364   0.272727     79\n",
      "2     0.272727   0.409091     77\n",
      "..         ...        ...    ...\n",
      "147  15.818182  15.954545     72\n",
      "148  15.954545  16.090909     76\n",
      "149  16.090909  16.227273     79\n",
      "150  16.227273  16.363636     84\n",
      "151  16.363636  16.636364     72\n",
      "\n",
      "[152 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "for midi_file in midi_files:\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    song_dict = {\n",
    "        \"start\": [],\n",
    "        \"end\": [],\n",
    "        \"pitch\": [],\n",
    "    }\n",
    "    for note in midi_data.instruments[0].notes:\n",
    "        song_dict[\"start\"].append(note.start)\n",
    "        song_dict[\"end\"].append(note.end)\n",
    "        song_dict[\"pitch\"].append(note.pitch)\n",
    "    data_dict[midi_file.split(\"\\\\\")[-1].split(\".\")[0]] = pd.DataFrame(song_dict).sort_values(by=['start', 'end'])\n",
    "\n",
    "dict_key = list(data_dict.keys())[0]\n",
    "print(f'{dict_key}\\n{\"-\"*40}\\n{data_dict[dict_key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitch\n",
      "Min: 17\tMax: 105\n"
     ]
    }
   ],
   "source": [
    "min_pitch, max_pitch = np.inf , 0\n",
    "\n",
    "for song in data_dict.values():\n",
    "    min_pitch = min(min_pitch, song['pitch'].min())\n",
    "    max_pitch = max(max_pitch, song['pitch'].max())\n",
    "\n",
    "print(f'Pitch\\nMin: {min_pitch}\\tMax: {max_pitch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in previous snippet, the pitch of the notes vary from 17 to 105 in value, which can be translated from 21.83 Hz to 3520 Hz.\n",
    "In a regular piano, the note of 21.83Hz is not achievable. The piano notes only start from 27.50Hz, which is the note A0, in MIDI pitch value of 21.\n",
    "Having this in mind we can remove all notes under the pitch value of 21.\n",
    "\n",
    "The max pitch value of 105 (or A7, 3520Hz) is valid for piano, so we don't need to trim in the high-pitch side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitch\n",
      "Min: 21\tMax: 105\n"
     ]
    }
   ],
   "source": [
    "for song in data_dict.values():\n",
    "    song.drop(song[song['pitch'] < 21].index, inplace=True)\n",
    "\n",
    "min_pitch, max_pitch = np.inf , 0\n",
    "\n",
    "for song in data_dict.values():\n",
    "    min_pitch = min(min_pitch, song['pitch'].min())\n",
    "    max_pitch = max(max_pitch, song['pitch'].max())\n",
    "\n",
    "print(f'Pitch\\nMin: {min_pitch}\\tMax: {max_pitch}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing invalid pitch values, the values can be normalized between the min and max values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for song in data_dict.values():\n",
    "    song['pitch'] = (song['pitch'] - 21) / (105 - 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160_EIGHTMEASURE_EXERCISES_NO_1\n",
      "----------------------------------------\n",
      "         start        end     pitch\n",
      "0     0.000000   0.136364  0.654762\n",
      "3     0.000000   0.545455  0.464286\n",
      "4     0.000000   0.545455  0.547619\n",
      "1     0.136364   0.272727  0.690476\n",
      "2     0.272727   0.409091  0.666667\n",
      "..         ...        ...       ...\n",
      "147  15.818182  15.954545  0.607143\n",
      "148  15.954545  16.090909  0.654762\n",
      "149  16.090909  16.227273  0.690476\n",
      "150  16.227273  16.363636  0.750000\n",
      "151  16.363636  16.636364  0.607143\n",
      "\n",
      "[152 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dict_key = list(data_dict.keys())[0]\n",
    "print(f'{dict_key}\\n{\"-\"*40}\\n{data_dict[dict_key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs: 702\n",
      "\n",
      "About number of notes per song:\n",
      "count      702.000000\n",
      "mean      1135.841880\n",
      "std       1299.012596\n",
      "min         55.000000\n",
      "25%        372.250000\n",
      "50%        667.500000\n",
      "75%       1397.500000\n",
      "max      10503.000000\n",
      "dtype: float64\n",
      "\n",
      "About note duration (in seconds):\n",
      "count    797361.000000\n",
      "mean          0.415640\n",
      "std           0.475599\n",
      "min           0.002273\n",
      "25%           0.168182\n",
      "50%           0.250000\n",
      "75%           0.500000\n",
      "max          32.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of songs: {len(data_dict.keys())}\\n\")\n",
    "\n",
    "number_of_notes_per_song = pd.Series([df.shape[0] for df in data_dict.values()])\n",
    "print(\"About number of notes per song:\")\n",
    "print(number_of_notes_per_song.describe())\n",
    "\n",
    "note_duration = pd.Series(dtype='float64')\n",
    "for song in data_dict.values():\n",
    "    note_duration = pd.concat([note_duration, song['end'] - song['start']])\n",
    "print(\"\\nAbout note duration (in seconds):\")\n",
    "print(note_duration.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the data can be stored as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.\\\\data\\\\treated_data.json', 'w+') as f:\n",
    "    data_to_store = {}\n",
    "    for song in data_dict:\n",
    "        data_to_store.update({song: data_dict[song].to_json()})\n",
    "    json.dump(data_to_store, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9557642ed31844b903319b561864a8ef0da5c7b931996e0f6ddf8b44d6bc5235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
